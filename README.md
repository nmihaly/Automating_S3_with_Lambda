
```markdown
ğŸ“‚ Automating S3 with Lambda

A hands-on AWS Lambda project that validates `.csv` files uploaded to an S3 bucket. If the file fails validation, it's automatically moved to an error bucket for review â€” a simple and efficient serverless workflow for file validation pipelines.

---

ğŸ§  Overview

This project demonstrates how to:

- Use AWS Lambda to process and validate `.csv` files
- Read S3 events to trigger Lambda functions
- Apply validation logic to file contents
- Move invalid files to a separate S3 error bucket
- Set up and test Lambda functions locally using SAM (Serverless Application Model)

---

ğŸ“‹ Features

- âœ… Validates product line, currency, bill amount, and date fields
- âš™ï¸ Built with Python 3.12 and Boto3
- â˜ï¸ Runs on AWS Lambda, triggered by S3 events
- ğŸ”„ Automatically deletes invalid files from the source bucket
- ğŸ§ª Includes local testing setup using `sam local invoke`

---

ğŸ“ Folder Structure

.
â”œâ”€â”€ lambda\_function.py      # Main Lambda code
â”œâ”€â”€ template.yaml           # SAM template for local testing
â”œâ”€â”€ event.json              # Sample S3 event trigger
â”œâ”€â”€ test\_data/              # Sample CSV files for testing
â””â”€â”€ README.md               # You're here

````

---

### ğŸš€ Getting Started

### 1. Prerequisites

- AWS CLI configured
- AWS Toolkit for VS Code (recommended)
- Python 3.12
- Docker (for local testing)
- SAM CLI

### 2. Clone the Repo

```bash
git clone https://github.com/nmihaly/Automating_S3_with_Lambda.git
cd Automating_S3_with_Lambda
````

### 3. Set Up Resources

Create two S3 buckets:

* `billing-2025` â€“ upload bucket
* `billing-errors-2025` â€“ error bucket

Upload a test `.csv` to the upload bucket before testing.

---

## ğŸ§ª Local Testing (SAM)

### Edit `event.json` with your S3 bucket and file name:

```json
{
  "Records": [
    {
      "s3": {
        "bucket": { "name": "billing-2025" },
        "object": { "key": "billing_data_meat_may_2023.csv" }
      }
    }
  ]
}
```

### Run the test:

```bash
sam local invoke -e event.json
```

Expected output (if validation fails):

```
Error in record 11: Date 5/11/2023 is not in the correct format (YYYY-MM-DD).
Moved erroneous file to: billing-errors-2025.
Deleted original file from bucket.
```

---

## ğŸ“Œ Validation Rules

Each row is checked for:

* âœ… **Valid product line**: Must be one of `['Bakery', 'Meat', 'Dairy']`
* ğŸ’µ **Valid currency**: `USD`, `CAD`, or `MXN`
* ğŸ’° **Non-negative bill amount**
* ğŸ“… **Date format**: Must be `YYYY-MM-DD`

Files that fail validation are copied to the error bucket and deleted from the source.

---

## âš¡ Deploy to AWS

1. Upload the Lambda code using the AWS Toolkit
2. In the Lambda console, attach the `AmazonS3FullAccess` policy to your execution role *(for testing only)*
3. Add an S3 trigger:

   * Source: `billing-2025`
   * Event type: `PUT`

Now every `.csv` uploaded to `billing-2025` will trigger the Lambda function automatically.

---

## ğŸ›  Example Use Cases

* Financial document validation pipelines
* Real-time ingestion validation for SaaS billing tools
* Preprocessing raw data before analytics workflows

---

## ğŸ“„ License

MIT License â€” free to use, modify, and distribute.

---

## ğŸ¤ Let's Connect

Have ideas to extend this? Need help with Lambda, S3, or Python on AWS?

Feel free to connect on [LinkedIn](https://www.linkedin.com/in/nmihaly) or open an issue!
